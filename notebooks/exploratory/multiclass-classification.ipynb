{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7021f769",
   "metadata": {},
   "source": [
    "## Multiclass-Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cb702e",
   "metadata": {},
   "source": [
    "## Multiclass-Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e260429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Import Libraries ---\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ba672d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>product_filled</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 i have a 3g iphone. after 3 hrs twe...</td>\n",
       "      <td>negative</td>\n",
       "      <td>iphone</td>\n",
       "      <td>3g iphone 3 hrs tweeting rise_austin dead need...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee know about @fludapp ? awesome ipad/i...</td>\n",
       "      <td>positive</td>\n",
       "      <td>ipad or iphone app</td>\n",
       "      <td>know awesome ipadiphone app youll likely appre...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin can not wait for #ipad 2 also. the...</td>\n",
       "      <td>positive</td>\n",
       "      <td>ipad</td>\n",
       "      <td>wait ipad 2 also sale sxsw</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw i hope this year's festival isn't as cra...</td>\n",
       "      <td>negative</td>\n",
       "      <td>ipad or iphone app</td>\n",
       "      <td>hope years festival isnt crashy years iphone a...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on fri #sxsw: marissa m...</td>\n",
       "      <td>positive</td>\n",
       "      <td>google</td>\n",
       "      <td>great stuff fri sxsw marissa mayer google tim ...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet   emotion  \\\n",
       "0  .@wesley83 i have a 3g iphone. after 3 hrs twe...  negative   \n",
       "1  @jessedee know about @fludapp ? awesome ipad/i...  positive   \n",
       "2  @swonderlin can not wait for #ipad 2 also. the...  positive   \n",
       "3  @sxsw i hope this year's festival isn't as cra...  negative   \n",
       "4  @sxtxstate great stuff on fri #sxsw: marissa m...  positive   \n",
       "\n",
       "       product_filled                                     cleaned_tweets  \\\n",
       "0              iphone  3g iphone 3 hrs tweeting rise_austin dead need...   \n",
       "1  ipad or iphone app  know awesome ipadiphone app youll likely appre...   \n",
       "2                ipad                         wait ipad 2 also sale sxsw   \n",
       "3  ipad or iphone app  hope years festival isnt crashy years iphone a...   \n",
       "4              google  great stuff fri sxsw marissa mayer google tim ...   \n",
       "\n",
       "   text_length  \n",
       "0           12  \n",
       "1           14  \n",
       "2            6  \n",
       "3            9  \n",
       "4           15  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 2. Load Data ---\n",
    "text_cleaned = pd.read_csv(\"../../assets/Cleaned_Tweets.csv\")\n",
    "text_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f60d9a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>product_filled</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 i have a 3g iphone. after 3 hrs twe...</td>\n",
       "      <td>negative</td>\n",
       "      <td>iphone</td>\n",
       "      <td>3g iphone 3 hrs tweeting rise_austin dead need...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee know about @fludapp ? awesome ipad/i...</td>\n",
       "      <td>positive</td>\n",
       "      <td>ipad or iphone app</td>\n",
       "      <td>know awesome ipadiphone app youll likely appre...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin can not wait for #ipad 2 also. the...</td>\n",
       "      <td>positive</td>\n",
       "      <td>ipad</td>\n",
       "      <td>wait ipad 2 also sale sxsw</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw i hope this year's festival isn't as cra...</td>\n",
       "      <td>negative</td>\n",
       "      <td>ipad or iphone app</td>\n",
       "      <td>hope years festival isnt crashy years iphone a...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on fri #sxsw: marissa m...</td>\n",
       "      <td>positive</td>\n",
       "      <td>google</td>\n",
       "      <td>great stuff fri sxsw marissa mayer google tim ...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9087</th>\n",
       "      <td>ipad everywhere. #sxsw {link}</td>\n",
       "      <td>positive</td>\n",
       "      <td>ipad</td>\n",
       "      <td>ipad everywhere sxsw link</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>wave, buzz... rt @mention we interrupt your re...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>google</td>\n",
       "      <td>wave buzz rt interrupt regularly scheduled sxs...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>google's zeiger, a physician never reported po...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>google</td>\n",
       "      <td>googles zeiger physician never reported potent...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>some verizon iphone customers complained their...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>iphone</td>\n",
       "      <td>verizon iphone customers complained time fell ...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>ï¡ïàü_êîò£áââ_£â_ûârt @...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>google</td>\n",
       "      <td>ïïàü_êîòáââ_â_ûârt google tests ûïcheckin offe...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8936 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet   emotion  \\\n",
       "0     .@wesley83 i have a 3g iphone. after 3 hrs twe...  negative   \n",
       "1     @jessedee know about @fludapp ? awesome ipad/i...  positive   \n",
       "2     @swonderlin can not wait for #ipad 2 also. the...  positive   \n",
       "3     @sxsw i hope this year's festival isn't as cra...  negative   \n",
       "4     @sxtxstate great stuff on fri #sxsw: marissa m...  positive   \n",
       "...                                                 ...       ...   \n",
       "9087                      ipad everywhere. #sxsw {link}  positive   \n",
       "9088  wave, buzz... rt @mention we interrupt your re...   neutral   \n",
       "9089  google's zeiger, a physician never reported po...   neutral   \n",
       "9090  some verizon iphone customers complained their...   neutral   \n",
       "9091  ï¡ïàü_êîò£áââ_£â_ûârt @...   neutral   \n",
       "\n",
       "          product_filled                                     cleaned_tweets  \\\n",
       "0                 iphone  3g iphone 3 hrs tweeting rise_austin dead need...   \n",
       "1     ipad or iphone app  know awesome ipadiphone app youll likely appre...   \n",
       "2                   ipad                         wait ipad 2 also sale sxsw   \n",
       "3     ipad or iphone app  hope years festival isnt crashy years iphone a...   \n",
       "4                 google  great stuff fri sxsw marissa mayer google tim ...   \n",
       "...                  ...                                                ...   \n",
       "9087                ipad                          ipad everywhere sxsw link   \n",
       "9088              google  wave buzz rt interrupt regularly scheduled sxs...   \n",
       "9089              google  googles zeiger physician never reported potent...   \n",
       "9090              iphone  verizon iphone customers complained time fell ...   \n",
       "9091              google  ïïàü_êîòáââ_â_ûârt google tests ûïcheckin offe...   \n",
       "\n",
       "      text_length  \n",
       "0              12  \n",
       "1              14  \n",
       "2               6  \n",
       "3               9  \n",
       "4              15  \n",
       "...           ...  \n",
       "9087            4  \n",
       "9088           14  \n",
       "9089           17  \n",
       "9090           14  \n",
       "9091            7  \n",
       "\n",
       "[8936 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_df = text_cleaned[text_cleaned[\"emotion\"].isin(['positive', 'negative','neutral'])]\n",
    "binary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bee50f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_binary = binary_df[\"cleaned_tweets\"]\n",
    "y_binary = binary_df[\"emotion\"]\n",
    "\n",
    "y_binary = y_binary.map({'negative': 0, 'positive': 1, 'neutral': 2})\n",
    "\n",
    "\n",
    "Xmultib_train, Xmultib_test, ymultib_train, ymultib_test = train_test_split(\n",
    "    X_binary, y_binary, test_size=0.2, random_state=42, stratify=y_binary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53b19fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmultib_temp, Xmultib_val, ymultib_temp, ymultib_val= train_test_split(\n",
    "    Xmultib_train, ymultib_train, test_size=0.2, random_state=42, stratify=ymultib_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a014994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.09      0.16        91\n",
      "           1       0.63      0.47      0.54       477\n",
      "           2       0.70      0.87      0.78       862\n",
      "\n",
      "    accuracy                           0.69      1430\n",
      "   macro avg       0.74      0.48      0.49      1430\n",
      "weighted avg       0.69      0.69      0.66      1430\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  8  18  65]\n",
      " [  1 225 251]\n",
      " [  0 113 749]]\n"
     ]
    }
   ],
   "source": [
    "# Define pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "sentiment_pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=5000, ngram_range=(1,2))),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Fit pipeline\n",
    "sentiment_pipeline.fit(Xmultib_temp, ymultib_temp)\n",
    "\n",
    "# Predictions\n",
    "y_pred = sentiment_pipeline.predict(Xmultib_val)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Classification Report:\\n\", classification_report(ymultib_val, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(ymultib_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351f2d68",
   "metadata": {},
   "source": [
    "- The model performs **best on class 2** (good recall and precision).  \n",
    "- It struggles **heavily with class 0**, where most samples are wrongly classified as class 2.  \n",
    "- Class 1 has **moderate performance**, but a large portion is still misclassified as class 2.  \n",
    "- The imbalance in class distribution (class 2 has the most samples) likely contributes to the poor recall of minority classes (especially class 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f126c9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.42      0.35        91\n",
      "           1       0.56      0.59      0.57       477\n",
      "           2       0.75      0.70      0.72       862\n",
      "\n",
      "    accuracy                           0.64      1430\n",
      "   macro avg       0.54      0.57      0.55      1430\n",
      "weighted avg       0.66      0.64      0.65      1430\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 38  22  31]\n",
      " [ 29 282 166]\n",
      " [ 57 204 601]]\n"
     ]
    }
   ],
   "source": [
    "# Define pipeline\n",
    "# Managing class imbalance with SMOTE\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "smote_pipeline = ImbPipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=5000, ngram_range=(1,2))),\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, class_weight=None))  # class_weight not needed since we use SMOTE\n",
    "])\n",
    "\n",
    "# Fit pipeline\n",
    "smote_pipeline.fit(Xmultib_temp, ymultib_temp)\n",
    "\n",
    "# Predictions\n",
    "y_pred = smote_pipeline.predict(Xmultib_val)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Classification Report:\\n\", classification_report(ymultib_val, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(ymultib_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46d5c43",
   "metadata": {},
   "source": [
    "1. **SMOTE greatly improved recall for Class 0**, which was nearly ignored before.  \n",
    "2. The model is now **more balanced across all three classes** (macro recall improved from 0.48 → 0.57).  \n",
    "3. Accuracy dropped slightly (69% → 64%), but this is expected because the model now prioritizes **fairness across classes** instead of always favoring the majority class.  \n",
    "4. Trade-off: More false positives for Class 0, but much better representation overall.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d836f3a5",
   "metadata": {},
   "source": [
    "## GRID SEARCH      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b0f20af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 21\u001b[0m\n\u001b[0;32m     11\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     12\u001b[0m     smote_pipeline,\n\u001b[0;32m     13\u001b[0m     param_grid,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Fit grid search\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(Xmultib_train, ymultib_train)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Best parameters\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1571\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    967\u001b[0m         )\n\u001b[0;32m    968\u001b[0m     )\n\u001b[1;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    971\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    972\u001b[0m         clone(base_estimator),\n\u001b[0;32m    973\u001b[0m         X,\n\u001b[0;32m    974\u001b[0m         y,\n\u001b[0;32m    975\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    976\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    977\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    978\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    979\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    980\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    981\u001b[0m     )\n\u001b[0;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    983\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    984\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    985\u001b[0m     )\n\u001b[0;32m    986\u001b[0m )\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[0;32m   1790\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[0;32m   1791\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1795\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[0;32m   1796\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[0;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[0;32m   1799\u001b[0m     ):\n\u001b[1;32m-> 1800\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1801\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1804\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[0;32m   1805\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1811\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[0;32m   1812\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV     \n",
    "param_grid = {\n",
    "    \"tfidf__max_features\": [3000, 5000, 7000],\n",
    "    \"tfidf__ngram_range\": [(1,1), (1,2)],\n",
    "    \"clf__C\": [0.01, 0.1, 1, 10],\n",
    "    \"clf__solver\": [\"liblinear\", \"lbfgs\"],\n",
    "    \"clf__penalty\": [\"l2\"]  # liblinear & lbfgs both work with L2\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "grid_search = GridSearchCV(\n",
    "    smote_pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"f1_macro\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(Xmultib_train, ymultib_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(Xmultib_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(\"\\nClassification Report:\\n\", classification_report(ymultib_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(ymultib_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341ddb86",
   "metadata": {},
   "source": [
    "Interpretation by Class\n",
    "\n",
    "1. Class 0 (minority, 114 samples):\n",
    "\n",
    "- Recall improved to 0.53, meaning the model is now catching more than half of these cases.\n",
    "- Precision is lower (0.41), showing some false positives, but this is a fair trade-off for better recall.\n",
    "\n",
    "2. Class 1 (596 samples):\n",
    "\n",
    "- Balanced performance (Precision = 0.58, Recall = 0.64, F1 = 0.61).\n",
    "- Model is doing better than before in both capturing class 1 and keeping false positives under control.\n",
    "\n",
    "3. Class 2 (majority, 1078 samples):\n",
    "\n",
    "- Strongest performance overall: Precision = 0.77, Recall = 0.70.\n",
    "- Slight trade-off between recall and precision, but still the best-performing class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb4f2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Accuracy: 0.6399\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.35      0.34        91\n",
      "           1       0.55      0.60      0.57       477\n",
      "           2       0.74      0.69      0.72       862\n",
      "\n",
      "    accuracy                           0.64      1430\n",
      "   macro avg       0.54      0.55      0.54      1430\n",
      "weighted avg       0.65      0.64      0.64      1430\n",
      "\n",
      "\n",
      "Random Forest Accuracy: 0.6874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.22      0.31        91\n",
      "           1       0.64      0.50      0.56       477\n",
      "           2       0.71      0.84      0.77       862\n",
      "\n",
      "    accuracy                           0.69      1430\n",
      "   macro avg       0.62      0.52      0.55      1430\n",
      "weighted avg       0.67      0.69      0.67      1430\n",
      "\n",
      "\n",
      "Random Forest Accuracy: 0.6874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.22      0.31        91\n",
      "           1       0.64      0.50      0.56       477\n",
      "           2       0.71      0.84      0.77       862\n",
      "\n",
      "    accuracy                           0.69      1430\n",
      "   macro avg       0.62      0.52      0.55      1430\n",
      "weighted avg       0.67      0.69      0.67      1430\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [15:21:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Accuracy: 0.6601\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.21      0.26        91\n",
      "           1       0.61      0.45      0.52       477\n",
      "           2       0.70      0.82      0.76       862\n",
      "\n",
      "    accuracy                           0.66      1430\n",
      "   macro avg       0.54      0.49      0.51      1430\n",
      "weighted avg       0.64      0.66      0.64      1430\n",
      "\n",
      "\n",
      "Gradient Boosting Accuracy: 0.6168\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.35      0.26        91\n",
      "           1       0.58      0.44      0.50       477\n",
      "           2       0.70      0.74      0.72       862\n",
      "\n",
      "    accuracy                           0.62      1430\n",
      "   macro avg       0.50      0.51      0.49      1430\n",
      "weighted avg       0.63      0.62      0.62      1430\n",
      "\n",
      "\n",
      "Summary of Results: {'SVM': 0.6398601398601399, 'Random Forest': 0.6874125874125874, 'XGBoost': 0.6601398601398601, 'Gradient Boosting': 0.6167832167832168}\n",
      "\n",
      "Gradient Boosting Accuracy: 0.6168\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.35      0.26        91\n",
      "           1       0.58      0.44      0.50       477\n",
      "           2       0.70      0.74      0.72       862\n",
      "\n",
      "    accuracy                           0.62      1430\n",
      "   macro avg       0.50      0.51      0.49      1430\n",
      "weighted avg       0.63      0.62      0.62      1430\n",
      "\n",
      "\n",
      "Summary of Results: {'SVM': 0.6398601398601399, 'Random Forest': 0.6874125874125874, 'XGBoost': 0.6601398601398601, 'Gradient Boosting': 0.6167832167832168}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"SVM\": LinearSVC(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, clf in models.items():\n",
    "    pipe = ImbPipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(max_features=5000, ngram_range=(1,2))),\n",
    "        (\"smote\", SMOTE(random_state=42)),\n",
    "        (\"clf\", clf)\n",
    "    ])\n",
    "    \n",
    "     # Fit\n",
    "    pipe.fit(Xmultib_temp, ymultib_temp)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = pipe.predict(Xmultib_val)\n",
    "    \n",
    "    # Evaluate\n",
    "    acc = accuracy_score(ymultib_val, y_pred)\n",
    "    print(f\"\\n{name} Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(ymultib_val, y_pred))\n",
    "    \n",
    "    results[name] = acc\n",
    "\n",
    "print(\"\\nSummary of Results:\", results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fc7c31",
   "metadata": {},
   "source": [
    "tuning the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c5ea3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Running GridSearch for SVM...\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "SVM Best Params: {'clf__C': 1}\n",
      "SVM Accuracy: 0.6399\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.35      0.34        91\n",
      "           1       0.55      0.60      0.57       477\n",
      "           2       0.74      0.69      0.72       862\n",
      "\n",
      "    accuracy                           0.64      1430\n",
      "   macro avg       0.54      0.55      0.54      1430\n",
      "weighted avg       0.65      0.64      0.64      1430\n",
      "\n",
      "\n",
      " Running GridSearch for Random Forest...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "SVM Best Params: {'clf__C': 1}\n",
      "SVM Accuracy: 0.6399\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.35      0.34        91\n",
      "           1       0.55      0.60      0.57       477\n",
      "           2       0.74      0.69      0.72       862\n",
      "\n",
      "    accuracy                           0.64      1430\n",
      "   macro avg       0.54      0.55      0.54      1430\n",
      "weighted avg       0.65      0.64      0.64      1430\n",
      "\n",
      "\n",
      " Running GridSearch for Random Forest...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Random Forest Best Params: {'clf__max_depth': None, 'clf__n_estimators': 200}\n",
      "Random Forest Accuracy: 0.6874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.22      0.31        91\n",
      "           1       0.64      0.50      0.56       477\n",
      "           2       0.71      0.84      0.77       862\n",
      "\n",
      "    accuracy                           0.69      1430\n",
      "   macro avg       0.62      0.52      0.55      1430\n",
      "weighted avg       0.67      0.69      0.67      1430\n",
      "\n",
      "\n",
      " Running GridSearch for XGBoost...\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "Random Forest Best Params: {'clf__max_depth': None, 'clf__n_estimators': 200}\n",
      "Random Forest Accuracy: 0.6874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.22      0.31        91\n",
      "           1       0.64      0.50      0.56       477\n",
      "           2       0.71      0.84      0.77       862\n",
      "\n",
      "    accuracy                           0.69      1430\n",
      "   macro avg       0.62      0.52      0.55      1430\n",
      "weighted avg       0.67      0.69      0.67      1430\n",
      "\n",
      "\n",
      " Running GridSearch for XGBoost...\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 46\u001b[0m\n\u001b[0;32m     39\u001b[0m pipe \u001b[38;5;241m=\u001b[39m ImbPipeline([\n\u001b[0;32m     40\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtfidf\u001b[39m\u001b[38;5;124m\"\u001b[39m, TfidfVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m, ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m))),\n\u001b[0;32m     41\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmote\u001b[39m\u001b[38;5;124m\"\u001b[39m, SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)),\n\u001b[0;32m     42\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclf\u001b[39m\u001b[38;5;124m\"\u001b[39m, clf)\n\u001b[0;32m     43\u001b[0m ])\n\u001b[0;32m     45\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(pipe, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 46\u001b[0m grid\u001b[38;5;241m.\u001b[39mfit(Xmultib_temp, ymultib_temp)\n\u001b[0;32m     48\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mpredict(Xmultib_val)\n\u001b[0;32m     50\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(ymultib_val, y_pred)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1571\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    967\u001b[0m         )\n\u001b[0;32m    968\u001b[0m     )\n\u001b[1;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    971\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    972\u001b[0m         clone(base_estimator),\n\u001b[0;32m    973\u001b[0m         X,\n\u001b[0;32m    974\u001b[0m         y,\n\u001b[0;32m    975\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    976\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    977\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    978\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    979\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    980\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    981\u001b[0m     )\n\u001b[0;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    983\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    984\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    985\u001b[0m     )\n\u001b[0;32m    986\u001b[0m )\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[0;32m   1790\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[0;32m   1791\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1795\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[0;32m   1796\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[0;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[0;32m   1799\u001b[0m     ):\n\u001b[1;32m-> 1800\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1801\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1804\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[0;32m   1805\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1811\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[0;32m   1812\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define models and param grids\n",
    "models_and_params = {\n",
    "    \"SVM\": (\n",
    "        LinearSVC(random_state=42),\n",
    "        {\n",
    "            \"clf__C\": [0.1, 1, 10]\n",
    "        }\n",
    "    ),\n",
    "    \"Random Forest\": (\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        {\n",
    "            \"clf__n_estimators\": [100, 200],\n",
    "            \"clf__max_depth\": [None, 10, 20]\n",
    "        }\n",
    "    ),\n",
    "    \"XGBoost\": (\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42),\n",
    "        {\n",
    "            \"clf__n_estimators\": [100, 200],\n",
    "            \"clf__max_depth\": [3, 6, 10],\n",
    "            \"clf__learning_rate\": [0.1, 0.3]\n",
    "        }\n",
    "    ),\n",
    "    \"Gradient Boosting\": (\n",
    "        GradientBoostingClassifier(random_state=42),\n",
    "        {\n",
    "            \"clf__n_estimators\": [100, 200],\n",
    "            \"clf__learning_rate\": [0.05, 0.1, 0.3],\n",
    "            \"clf__max_depth\": [3, 5]\n",
    "        }\n",
    "    )\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, (clf, param_grid) in models_and_params.items():\n",
    "    print(f\"\\n Running GridSearch for {name}...\")\n",
    "    \n",
    "    pipe = ImbPipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(max_features=5000, ngram_range=(1,2))),\n",
    "        (\"smote\", SMOTE(random_state=42)),\n",
    "        (\"clf\", clf)\n",
    "    ])\n",
    "    \n",
    "    grid = GridSearchCV(pipe, param_grid, cv=3, scoring=\"accuracy\", n_jobs=-1, verbose=1)\n",
    "    grid.fit(Xmultib_temp, ymultib_temp)\n",
    "    \n",
    "    y_pred = grid.predict(Xmultib_val)\n",
    "    \n",
    "    acc = accuracy_score(ymultib_val, y_pred)\n",
    "    print(f\"{name} Best Params: {grid.best_params_}\")\n",
    "    print(f\"{name} Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(ymultib_val, y_pred))\n",
    "    \n",
    "    results[name] = {\"Accuracy\": acc, \"Best Params\": grid.best_params_}\n",
    "\n",
    "print(\"\\n Summary of Results:\")\n",
    "for model, res in results.items():\n",
    "    print(f\"{model}: Accuracy={res['Accuracy']:.4f}, Best Params={res['Best Params']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce554f21",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73738a1b",
   "metadata": {},
   "source": [
    "Using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c789d9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use same labels as your notebook\n",
    "label2id = {\"negative\": 0, \"positive\": 1, \"neutral\": 2}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "df = pd.DataFrame({\"text\": X_binary, \"label\": y_binary})\n",
    "\n",
    "# Train/val/test split\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    df[\"text\"], df[\"label\"], test_size=0.3, stratify=df[\"label\"], random_state=42\n",
    ")\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42\n",
    ")\n",
    "\n",
    "train_df = pd.DataFrame({\"text\": train_texts, \"label\": train_labels})\n",
    "val_df   = pd.DataFrame({\"text\": val_texts, \"label\": val_labels})\n",
    "test_df  = pd.DataFrame({\"text\": test_texts, \"label\": test_labels})\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset   = Dataset.from_pandas(val_df)\n",
    "test_dataset  = Dataset.from_pandas(test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c1b02e",
   "metadata": {},
   "source": [
    "##  Tokenize Text with BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76271343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970b01eb9fa14a39936cf738fd83276a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6255 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2aabf75bc194145a8eea3383751ac33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1340 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87570a54085b44608bf6f04686fee2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1341 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "val_dataset   = val_dataset.map(tokenize, batched=True)\n",
    "test_dataset  = test_dataset.map(tokenize, batched=True)\n",
    "\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4a30eb",
   "metadata": {},
   "source": [
    "### Define BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1b94beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "num_labels = len(label2id)\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", \n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0406b3da",
   "metadata": {},
   "source": [
    "### Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6176b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"macro\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8232403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    do_eval=True,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a81a1fb",
   "metadata": {},
   "source": [
    "### Train BERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ebb28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22740\\984575968.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1167' max='1173' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1167/1173 13:47:43 < 04:15, 0.02 it/s, Epoch 2.98/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.696238</td>\n",
       "      <td>0.678358</td>\n",
       "      <td>0.425088</td>\n",
       "      <td>0.794384</td>\n",
       "      <td>0.431369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.746000</td>\n",
       "      <td>0.655312</td>\n",
       "      <td>0.711194</td>\n",
       "      <td>0.601812</td>\n",
       "      <td>0.648322</td>\n",
       "      <td>0.577742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    \n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c971c68",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9f5a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate(test_dataset)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d247e38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "preds_output = trainer.predict(test_dataset)\n",
    "y_preds = preds_output.predictions.argmax(-1)\n",
    "cm = confusion_matrix(test_labels, y_preds)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Negative\",\"Neutral\",\"Positive\"], yticklabels=[\"Negative\",\"Neutral\",\"Positive\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix - BERT Multiclass\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
