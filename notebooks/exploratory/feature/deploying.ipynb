{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7123f82f",
   "metadata": {},
   "source": [
    "## DEPLOYING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5345f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load trained pipeline\n",
    "pipeline = joblib.load(\"pipeline.pkl\")\n",
    "\n",
    "# Set threshold\n",
    "THRESHOLD = 0.4\n",
    "\n",
    "# Create Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return \"✅ Twitter Sentiment Analysis API is running!\"\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    try:\n",
    "        # Expect JSON input: {\"tweets\": [\"tweet1\", \"tweet2\"]}\n",
    "        data = request.get_json()\n",
    "\n",
    "        if not data or \"tweets\" not in data:\n",
    "            return jsonify({\"error\": \"Invalid input. Send JSON: {'tweets': ['...']}\"}), 400\n",
    "\n",
    "        texts = data[\"tweets\"]\n",
    "\n",
    "        # Get prediction probabilities\n",
    "        probs = pipeline.predict_proba(texts)[:, 1]\n",
    "\n",
    "        # Apply threshold\n",
    "        preds = (probs >= THRESHOLD).astype(int)\n",
    "\n",
    "        # Map to labels\n",
    "        labels = [\"negative\" if p == 0 else \"positive\" for p in preds]\n",
    "\n",
    "        return jsonify({\"predictions\": labels, \"probabilities\": probs.tolist()})\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0a511e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load your pre-trained pipeline\n",
    "pipeline = joblib.load('pipeline.pkl')\n",
    "\n",
    "# Threshold for negative class\n",
    "THRESHOLD = 0.4\n",
    "\n",
    "# Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Home route\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return \"Twitter Sentiment Analysis API is running!\"\n",
    "\n",
    "# Prediction route\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        texts = data['tweets']  # expects {\"tweets\": [\"tweet1\", \"tweet2\", ...]}\n",
    "        \n",
    "        # Get probabilities for positive class\n",
    "        probs = pipeline.predict_proba(texts)[:, 1]\n",
    "        \n",
    "        # Apply threshold\n",
    "        preds = (probs >= THRESHOLD).astype(int)\n",
    "        labels = [\"negative\" if p == 0 else \"positive\" for p in preds]\n",
    "        \n",
    "        return jsonify({\"predictions\": labels})\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84ad94a",
   "metadata": {},
   "source": [
    "Install Flask\n",
    "\n",
    "If you haven’t yet:\n",
    "\n",
    "pip install flask\n",
    "\n",
    "2️⃣ Create the app structure\n",
    "sentiment_app/\n",
    "│\n",
    "├─ app.py           # Main Flask app\n",
    "├─ text_pipeline.pkl # Your pipeline (TF-IDF + model)\n",
    "└─ requirements.txt # For deployment\n",
    "\n",
    "3️⃣ Flask app template (app.py)\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "\n",
    "# Load your pre-trained pipeline (replace with final model later)\n",
    "pipeline = joblib.load('text_pipeline.pkl')\n",
    "\n",
    "# Optional: define threshold for negative class\n",
    "THRESHOLD = 0.4\n",
    "\n",
    "# Flask app\n",
    "app = Flask(_name_)\n",
    "\n",
    "# Home route\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return \"Twitter Sentiment Analysis API is running!\"\n",
    "\n",
    "# Prediction route\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        texts = data['tweets']  # expects {\"tweets\": [\"tweet1\", \"tweet2\", ...]}\n",
    "        \n",
    "        # Get probabilities for positive class\n",
    "        probs = pipeline.predict_proba(texts)[:,1]\n",
    "        \n",
    "        # Adjust threshold for class 0 if needed\n",
    "        preds = (probs >= THRESHOLD).astype(int)\n",
    "        labels = [\"negative\" if p==0 else \"positive\" for p in preds]\n",
    "        \n",
    "        return jsonify({\"predictions\": labels})\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)})\n",
    "\n",
    "# Run the app\n",
    "if _name_ == '_main_':\n",
    "    app.run(debug=True)\n",
    "\n",
    "4️⃣ Test locally\n",
    "\n",
    "Run the app:\n",
    "\n",
    "python app.py\n",
    "\n",
    "\n",
    "Send a POST request (you can use Postman or Python requests):\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"http://127.0.0.1:5000/predict\"\n",
    "data = {\"tweets\": [\"I love the new Apple iPhone!\", \"Android keeps crashing.\"]}\n",
    "\n",
    "response = requests.post(url, json=data)\n",
    "print(response.json())\n",
    "\n",
    "\n",
    "Expected output:\n",
    "\n",
    "{\"predictions\": [\"positive\", \"negative\"]}\n",
    "\n",
    "5️⃣ Notes\n",
    "\n",
    "You can replace text_pipeline.pkl with your final tuned model anytime — no changes to API code.\n",
    "\n",
    "Threshold is easily adjustable (THRESHOLD = 0.4) to improve negative tweet detection.\n",
    "\n",
    "This app is deployment-ready for Heroku, AWS, or any cloud provider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd5cd0b",
   "metadata": {},
   "source": [
    "Install FastAPI + Uvicorn\n",
    "pip install fastapi uvicorn\n",
    "\n",
    "2️⃣ Create the app structure\n",
    "sentiment_app/\n",
    "│\n",
    "├─ app.py           # FastAPI app\n",
    "├─ text_pipeline.pkl # Your pipeline (TF-IDF + model)\n",
    "└─ requirements.txt\n",
    "\n",
    "3️⃣ FastAPI app template (app.py)\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load your pre-trained pipeline\n",
    "pipeline = joblib.load('text_pipeline.pkl')\n",
    "\n",
    "# Threshold for negative class\n",
    "THRESHOLD = 0.4\n",
    "\n",
    "# FastAPI app\n",
    "app = FastAPI(title=\"Twitter Sentiment Analysis API\")\n",
    "\n",
    "# Define request model\n",
    "class Tweets(BaseModel):\n",
    "    tweets: list[str]\n",
    "\n",
    "# Home route\n",
    "@app.get(\"/\")\n",
    "def read_root():\n",
    "    return {\"message\": \"Twitter Sentiment Analysis API is running!\"}\n",
    "\n",
    "# Prediction route\n",
    "@app.post(\"/predict\")\n",
    "def predict(data: Tweets):\n",
    "    try:\n",
    "        texts = data.tweets\n",
    "        # Predict probabilities for positive class\n",
    "        probs = pipeline.predict_proba(texts)[:,1]\n",
    "        preds = (probs >= THRESHOLD).astype(int)\n",
    "        labels = [\"negative\" if p==0 else \"positive\" for p in preds]\n",
    "        return {\"predictions\": labels}\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=400, detail=str(e))\n",
    "\n",
    "4️⃣ Run the app\n",
    "uvicorn app:app --reload\n",
    "\n",
    "\n",
    "--reload allows hot-reloading when you edit the code.\n",
    "\n",
    "Open browser: http://127.0.0.1:8000 → you’ll see the home message.\n",
    "\n",
    "Swagger docs: http://127.0.0.1:8000/docs → interactive API testing.\n",
    "\n",
    "5️⃣ Test with Python\n",
    "import requests\n",
    "\n",
    "url = \"http://127.0.0.1:8000/predict\"\n",
    "data = {\"tweets\": [\"I love the new Apple iPhone!\", \"Android keeps crashing.\"]}\n",
    "response = requests.post(url, json=data)\n",
    "print(response.json())\n",
    "\n",
    "\n",
    "Expected:\n",
    "\n",
    "{\"predictions\": [\"positive\", \"negative\"]}\n",
    "\n",
    "✅ Advantages of FastAPI\n",
    "\n",
    "Auto-generates interactive docs (/docs) → great for demos.\n",
    "\n",
    "Supports async calls → scalable for many requests.\n",
    "\n",
    "Easy to swap in your final pipeline without changing any endpoint.\n",
    "\n",
    "Works well with Docker for cloud deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
